from dataloader import Dataloader, CovertypeDataloader, HelenaDataloader, DionisDataloader, HiggsDataloader, RoadSafetyDataloader, JannisDataloader, WineQualityDataloader, AllstateClaimsSeverityDataloader, HouseSalesDataloader, DiamondsDataloader
from flwr_datasets.partitioner import ExponentialPartitioner
from subsampling.mvs import MVS
import xgboost as xgb
import os
import csv

import matplotlib.pyplot as plt


def mvs_simulation():
    num_clients = 5
    dataset = CovertypeDataloader(ExponentialPartitioner(num_clients))
    mvs = MVS(dataset.get_objective())

    for client in range(num_clients):
        train_dmatrix, _ = dataset.get_train_dmatrix(client)
        test_dmatrix, _ = dataset.get_test_dmatrix(None)
        bst = xgb.Booster(dataset.get_params(), [train_dmatrix])

        preds = bst.predict(train_dmatrix, output_margin=True, training=True)
        new_train_dmatrix = mvs.subsample(preds, train_dmatrix)
        bst.update(new_train_dmatrix, bst.num_boosted_rounds())

        bst.save_model(f"_static/model_{bst.num_boosted_rounds()}_{client}.json")

        evaluate = bst.eval_set([(test_dmatrix, "test")])
        print("Validation: ", evaluate)


def mvs_simulation_centralized():
    num_clients = 5
    dataset = DionisDataloader(ExponentialPartitioner(num_clients))
    sample_rates = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
    
    train_dmatrix, _ = dataset.get_train_dmatrix()
    test_dmatrix, _ = dataset.get_test_dmatrix(None)
    
    all_results = {}

    for sample_rate in sample_rates:
        eval_results = []
        mvs = MVS(dataset.get_objective(), sample_rate=sample_rate)
        bst = xgb.Booster(dataset.get_params(), [train_dmatrix])
        for i in range(200):
            preds = bst.predict(train_dmatrix, output_margin=True, training=True)
            new_train_dmatrix = mvs.subsample(preds, train_dmatrix)
            bst.update(new_train_dmatrix, bst.num_boosted_rounds())

            evaluate = bst.eval_set([(test_dmatrix, "test")])
            auc = round(float(evaluate.split("\t")[1].split(":")[1]), 4)
            eval_results.append(auc)
            print("Validation: ", evaluate)
            # bst.save_model(f'xgboost_{sample_rate}_{i}.json')

        print(eval_results)
        all_results[sample_rate] = eval_results
    
    print(all_results)

def load_dataset_try():
    num_clients = 5
    dataset = DionisDataloader(ExponentialPartitioner(num_clients))
    train_dmatrix, _ = dataset.get_train_dmatrix()
    test_dmatrix, _ = dataset.get_test_dmatrix(None)

def dataset_analysis():
    num_clients = 5
    dataset = DionisDataloader(ExponentialPartitioner(num_clients))
    dataset.dataset_analysis()

def visualise():
    data = {
        0.1: [0.2774,0.2329,0.2257,0.2229,0.2235,0.2237,0.2246,0.2269,0.2282,0.2299,0.2326,0.2342,0.2378,0.2397,0.2403,0.2437,0.2445,0.2478,0.2513,0.2571,0.2572,0.2591,0.2604,0.2646,0.2658,0.2666,0.2687,0.2706,0.2727,0.2751,0.2788,0.2841,0.2884,0.2943,0.2928,0.2973,0.3047,0.3043,0.3043,0.3078,0.3077,0.3094,0.313,0.3178,0.3246,0.3282,0.3322,0.3347,0.3401,0.3431,0.3408,0.3437,0.3438,0.3477,0.3506,0.3531,0.3579,0.3613,0.3653,0.3709,0.3706,0.3752,0.3803,0.3871,0.3943,0.3978,0.4058,0.4055,0.4087,0.4087,0.4118,0.4141,0.4198,0.4249,0.4311,0.4401,0.4422,0.4428,0.4483,0.4499,0.4527,0.4579,0.4629,0.4623,0.467,0.4698,0.4755,0.4806,0.484,0.4885,0.493,0.4953,0.5038,0.5073,0.5117,0.5175,0.5177,0.5203,0.5238,0.5231],
        0.2: [0.2477,0.221,0.2113,0.2114,0.2113,0.2111,0.2113,0.2138,0.2172,0.2195,0.2218,0.2239,0.2264,0.2273,0.2299,0.2317,0.2355,0.2371,0.238,0.2401,0.2402,0.2417,0.2437,0.2477,0.2481,0.2496,0.2523,0.2553,0.2582,0.2585,0.2595,0.2602,0.2619,0.2646,0.2641,0.2654,0.2685,0.2712,0.274,0.275,0.2766,0.2802,0.284,0.2862,0.2886,0.289,0.2925,0.2933,0.2937,0.2948,0.2947,0.2981,0.3012,0.3022,0.3064,0.3077,0.3113,0.3132,0.3146,0.317,0.319,0.3197,0.3228,0.326,0.3273,0.3263,0.3267,0.3315,0.3304,0.331,0.3332,0.3364,0.3383,0.3409,0.3436,0.3448,0.3484,0.3506,0.3542,0.3547,0.3574,0.3604,0.3623,0.3648,0.3695,0.3696,0.3687,0.3705,0.3741,0.3742,0.3759,0.3778,0.3796,0.3811,0.3817,0.3837,0.3869,0.3883,0.3923,0.3945],
        0.3: [0.2392,0.2107,0.2036,0.2006,0.201,0.2016,0.2017,0.2033,0.2049,0.2054,0.2076,0.2091,0.2099,0.2115,0.2138,0.2142,0.217,0.2186,0.2212,0.222,0.2236,0.2258,0.2275,0.2279,0.2284,0.2292,0.2329,0.2339,0.2335,0.2345,0.2375,0.238,0.2398,0.2427,0.244,0.2436,0.244,0.2482,0.2483,0.2488,0.2481,0.2503,0.252,0.2523,0.255,0.2569,0.2581,0.2603,0.2589,0.2606,0.2624,0.2633,0.2641,0.2664,0.2678,0.2684,0.2682,0.2688,0.2698,0.2709,0.2721,0.2757,0.2766,0.2762,0.2769,0.2781,0.2789,0.2799,0.2813,0.2814,0.2811,0.2812,0.2826,0.2858,0.288,0.2894,0.2947,0.2933,0.2935,0.2944,0.2945,0.2977,0.2979,0.3005,0.301,0.3029,0.3055,0.3057,0.3076,0.3091,0.3106,0.3101,0.3122,0.3129,0.3141,0.3159,0.3162,0.3176,0.3193,0.3203],
        0.4: [0.2272,0.2055,0.1983,0.1964,0.1961,0.1966,0.1989,0.1997,0.2007,0.2015,0.2017,0.2013,0.2019,0.2032,0.2045,0.2062,0.2079,0.2095,0.2113,0.2116,0.212,0.2129,0.2143,0.2154,0.2172,0.2185,0.2189,0.221,0.2216,0.2228,0.2235,0.2242,0.225,0.2263,0.2253,0.2255,0.2266,0.228,0.229,0.2297,0.2312,0.232,0.233,0.2339,0.236,0.2362,0.2381,0.2389,0.239,0.2411,0.2425,0.2449,0.2446,0.2459,0.2466,0.2454,0.2475,0.2482,0.2494,0.2493,0.2508,0.2524,0.2541,0.2547,0.2565,0.2579,0.259,0.2589,0.2609,0.262,0.2626,0.2648,0.2664,0.2668,0.2687,0.2702,0.2713,0.2719,0.2722,0.2718,0.2731,0.2742,0.2752,0.2768,0.2776,0.2789,0.2783,0.2798,0.2805,0.2809,0.2807,0.2823,0.2829,0.283,0.2826,0.2823,0.2831,0.2833,0.2833,0.2842],
        0.5: [0.219,0.1988,0.1951,0.1925,0.1926,0.1929,0.1924,0.1931,0.1934,0.1937,0.1943,0.1964,0.1967,0.1986,0.1994,0.1997,0.1996,0.199,0.2004,0.2017,0.2019,0.2027,0.204,0.2047,0.2055,0.2061,0.2067,0.2076,0.2088,0.2095,0.211,0.211,0.2117,0.2128,0.2134,0.2142,0.2136,0.2135,0.2155,0.2165,0.2166,0.2183,0.2203,0.2213,0.2217,0.2229,0.2241,0.2245,0.2251,0.2254,0.2257,0.2261,0.2273,0.2278,0.2282,0.2279,0.2284,0.229,0.2303,0.2305,0.2308,0.2312,0.2317,0.2324,0.2323,0.2336,0.2344,0.2353,0.2359,0.2374,0.2376,0.2386,0.238,0.2387,0.2393,0.2404,0.2417,0.2428,0.243,0.2437,0.2448,0.2452,0.2462,0.2464,0.2462,0.2475,0.2477,0.2491,0.2499,0.2492,0.25,0.2503,0.2512,0.252,0.2545,0.2556,0.2559,0.2573,0.258,0.2583],
        0.6: [0.2281,0.199,0.1953,0.1934,0.193,0.1929,0.1927,0.193,0.1931,0.194,0.1941,0.1953,0.1969,0.1968,0.1976,0.1986,0.1994,0.2013,0.2027,0.2043,0.2053,0.2067,0.2084,0.2082,0.2087,0.2107,0.2114,0.2104,0.2094,0.2102,0.2102,0.2113,0.2118,0.2133,0.2141,0.2149,0.2152,0.2151,0.2161,0.2184,0.2184,0.2194,0.2197,0.2202,0.2208,0.222,0.2232,0.224,0.2248,0.2253,0.2252,0.2256,0.226,0.2265,0.227,0.2282,0.23,0.2299,0.2309,0.2313,0.2323,0.2329,0.2345,0.2351,0.2363,0.2375,0.2373,0.2376,0.2383,0.2386,0.2391,0.2397,0.2403,0.2406,0.242,0.2426,0.2434,0.2434,0.2437,0.2445,0.2445,0.2447,0.2459,0.247,0.248,0.2475,0.2488,0.2491,0.2505,0.2507,0.2508,0.2521,0.2527,0.2526,0.2535,0.2542,0.2544,0.2548,0.2553,0.2563],
        0.7: [0.2188,0.1963,0.1928,0.1914,0.1905,0.1891,0.1893,0.1885,0.1891,0.1888,0.1893,0.19,0.1904,0.1913,0.1925,0.1934,0.1942,0.1947,0.1959,0.1972,0.198,0.1995,0.2,0.2002,0.201,0.2024,0.2027,0.2035,0.2038,0.2032,0.2039,0.2055,0.2056,0.2057,0.2062,0.2071,0.2081,0.2088,0.2094,0.2112,0.2115,0.2124,0.2128,0.2121,0.2127,0.2135,0.2141,0.2138,0.2147,0.2159,0.2161,0.2161,0.217,0.2173,0.2176,0.2185,0.2188,0.2187,0.2192,0.2196,0.2198,0.2208,0.2207,0.2217,0.2226,0.2222,0.2229,0.2232,0.2244,0.2243,0.2245,0.225,0.2245,0.2244,0.2254,0.2265,0.2269,0.2269,0.2281,0.2281,0.2299,0.2296,0.2305,0.231,0.2308,0.2314,0.2323,0.2333,0.2332,0.2338,0.2334,0.2338,0.2351,0.2354,0.2354,0.2353,0.2361,0.2367,0.2373,0.2371],
        0.8: [0.2198,0.1957,0.1894,0.1866,0.1858,0.1847,0.1853,0.1855,0.1861,0.1863,0.1869,0.1883,0.189,0.1897,0.1897,0.1905,0.1912,0.1921,0.1933,0.194,0.1951,0.196,0.1963,0.1969,0.1971,0.198,0.1981,0.199,0.1995,0.2007,0.2016,0.2012,0.2011,0.2009,0.201,0.2017,0.2029,0.203,0.2036,0.2046,0.2055,0.2061,0.2066,0.2074,0.208,0.2087,0.2084,0.2087,0.2087,0.2093,0.2103,0.2102,0.2104,0.2116,0.2123,0.2119,0.2121,0.2122,0.2136,0.2145,0.2145,0.2149,0.2161,0.2173,0.2182,0.2177,0.2173,0.2179,0.2187,0.2198,0.2204,0.2215,0.2216,0.2216,0.2217,0.222,0.2224,0.2231,0.223,0.2232,0.224,0.2245,0.2248,0.2246,0.2256,0.2254,0.2259,0.226,0.2265,0.2271,0.2275,0.2281,0.2284,0.2289,0.2294,0.2299,0.2305,0.2313,0.2316,0.2318],
        0.9: [0.216,0.1926,0.189,0.1854,0.1847,0.1851,0.185,0.1846,0.1857,0.1851,0.1857,0.187,0.187,0.1881,0.1884,0.1883,0.1891,0.1902,0.1916,0.1919,0.1929,0.1938,0.1946,0.1951,0.195,0.1951,0.1952,0.1964,0.1966,0.1972,0.1984,0.1999,0.201,0.2024,0.2024,0.2029,0.2039,0.2044,0.2049,0.2056,0.2065,0.2075,0.2075,0.2084,0.2092,0.2094,0.2099,0.2109,0.2118,0.2122,0.2129,0.2135,0.2138,0.2146,0.2152,0.2152,0.2156,0.2165,0.2165,0.2167,0.2174,0.2176,0.2181,0.2184,0.2191,0.2197,0.2202,0.2203,0.2212,0.2209,0.2213,0.2216,0.2221,0.2236,0.2236,0.2238,0.2242,0.2247,0.2254,0.2257,0.226,0.2269,0.2276,0.2282,0.2282,0.228,0.228,0.2282,0.2288,0.2292,0.2289,0.2288,0.2296,0.2293,0.23,0.2303,0.2308,0.2308,0.2309,0.2307],
        1.0: [0.2154,0.1936,0.1891,0.1876,0.1867,0.1854,0.1856,0.1864,0.1864,0.1873,0.1876,0.1881,0.1888,0.1894,0.1905,0.191,0.1918,0.1918,0.1931,0.1934,0.194,0.195,0.196,0.1974,0.1976,0.1984,0.1986,0.1996,0.2006,0.2014,0.202,0.2035,0.2044,0.2063,0.2078,0.2091,0.2098,0.2107,0.2106,0.211,0.2113,0.2112,0.2116,0.2122,0.2127,0.2136,0.2139,0.2143,0.2147,0.2152,0.2156,0.216,0.2164,0.2176,0.2178,0.2189,0.219,0.22,0.2202,0.2206,0.2212,0.2221,0.2231,0.2236,0.2243,0.2253,0.2264,0.2263,0.2268,0.2276,0.2287,0.2296,0.2308,0.2315,0.2318,0.2329,0.2334,0.234,0.2346,0.2356,0.2365,0.2369,0.2378,0.2384,0.239,0.2393,0.2393,0.2393,0.2397,0.2404,0.2407,0.2412,0.2418,0.2423,0.2429,0.243,0.2438,0.2453,0.246,0.247],
    }

    plt.figure(figsize=(15, 10))
    for key, values in data.items():
        plt.plot(values, linewidth=2, label=key)

    fontsize = 18
    plt.legend(fontsize=fontsize, loc='lower left', bbox_to_anchor=(1, 0))
    plt.grid()
    plt.xticks(fontsize=fontsize)
    plt.yticks(fontsize=fontsize)
    plt.title('Federated GOSS - House_sales - 10 clients uniform local evaluation - 100 rounds', fontsize=20)
    plt.xlabel('Rounds', fontsize=fontsize)
    plt.ylabel('Model size in bytes', fontsize=fontsize)

    plt.tight_layout()
    plt.savefig('_static/house_sales_mvs_10_linear_100.png')

# load_dataset_try()
# visualise()

mvs_simulation_centralized()

# dataset_analysis()

def calculate_average(filename):
    with open(filename, 'r') as file:
        reader = csv.reader(file)
        numbers = [int(row[0]) for row in reader]
        return sum(numbers) / len(numbers) if numbers else 0

averages = []

# Assuming the CSV files are named '1.csv', '2.csv', ..., '100.csv'
for i in range(1, 101):
    filename = f'./_static/{i}.csv'
    if os.path.exists(filename):
        avg = calculate_average(filename)
        averages.append(round(avg, 1))
        os.remove(filename)
    else:
        averages.append(None)  # Or handle the missing file case as needed

# Output the list of averages
print(averages)
print("average: ", sum(averages) / len(averages))
