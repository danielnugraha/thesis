from dataloader import Dataloader, CovertypeDataloader, HelenaDataloader, DionisDataloader, HiggsDataloader, RoadSafetyDataloader, JannisDataloader, WineQualityDataloader, AllstateClaimsSeverityDataloader, HouseSalesDataloader, DiamondsDataloader
from flwr_datasets.partitioner import ExponentialPartitioner
from subsampling.mvs import MVS
import xgboost as xgb
import os
import csv

import matplotlib.pyplot as plt


def mvs_simulation():
    num_clients = 5
    dataset = CovertypeDataloader(ExponentialPartitioner(num_clients))
    mvs = MVS(dataset.get_objective())

    for client in range(num_clients):
        train_dmatrix, _ = dataset.get_train_dmatrix(client)
        test_dmatrix, _ = dataset.get_test_dmatrix(None)
        bst = xgb.Booster(dataset.get_params(), [train_dmatrix])

        preds = bst.predict(train_dmatrix, output_margin=True, training=True)
        new_train_dmatrix = mvs.subsample(preds, train_dmatrix)
        bst.update(new_train_dmatrix, bst.num_boosted_rounds())

        bst.save_model(f"_static/model_{bst.num_boosted_rounds()}_{client}.json")

        evaluate = bst.eval_set([(test_dmatrix, "test")])
        print("Validation: ", evaluate)


def mvs_simulation_centralized():
    num_clients = 5
    dataset = EyeMovementsDataloader(ExponentialPartitioner(num_clients))
    sample_rates = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
    
    train_dmatrix, _ = dataset.get_train_dmatrix()
    test_dmatrix, _ = dataset.get_test_dmatrix(None)
    
    all_results = {}

    for sample_rate in sample_rates:
        eval_results = []
        mvs = MVS(dataset.get_objective(), sample_rate=sample_rate)
        bst = xgb.Booster(dataset.get_params(), [train_dmatrix])
        for i in range(100):
            preds = bst.predict(train_dmatrix, output_margin=True, training=True)
            new_train_dmatrix = mvs.subsample(preds, train_dmatrix)
            bst.update(new_train_dmatrix, bst.num_boosted_rounds())

            evaluate = bst.eval_set([(test_dmatrix, "test")])
            auc = round(float(evaluate.split("\t")[1].split(":")[1]), 4)
            eval_results.append(auc)
            print("Validation: ", evaluate)
            # bst.save_model(f'xgboost_{sample_rate}_{i}.json')

        print(eval_results)
        all_results[sample_rate] = eval_results
    
    print(all_results)

def load_dataset_try():
    num_clients = 5
    dataset = DiamondsDataloader(ExponentialPartitioner(num_clients))
    train_dmatrix, _ = dataset.get_train_dmatrix()
    test_dmatrix, _ = dataset.get_test_dmatrix(None)

def dataset_analysis():
    num_clients = 5
    dataset = DionisDataloader(ExponentialPartitioner(num_clients))
    dataset.dataset_analysis()

def visualise():
    data = {
        0.1: [3456.3, 869.7, 1299.3, 2400.7, 2905.3, 3240.0, 3103.3, 3268.3, 3197.7, 3028.3, 3261.0, 3600.7, 2723.7, 3208.7, 2892.7, 2809.0, 3190.0, 3408.7, 2865.0, 3130.7, 3124.0, 3025.7, 3403.0, 2793.0, 2870.7, 2907.3, 2900.3, 2740.0, 3035.0, 2798.0, 2430.7, 2729.3, 2761.7, 3060.3, 2793.0, 2759.0, 2784.0, 2895.3, 2615.3, 2623.7, 2450.7, 2538.0, 2724.0, 2596.7, 2355.3, 2464.0, 1886.7, 2024.3, 2458.7, 1828.3, 2090.0, 1950.7, 1964.3, 1893.0, 1894.7, 1694.0, 2268.7, 2157.7, 2424.3, 1858.3, 2758.7, 1892.7, 2469.0, 1956.0, 2261.3, 1658.7, 2523.3, 1992.0, 1991.0, 1728.3, 2358.0, 1790.3, 2185.3, 1993.0, 2396.7, 1794.3, 2451.7, 1992.3, 2322.0, 1560.0, 2062.3, 1387.7, 1926.7, 1323.7, 1864.7, 1357.0, 1988.0, 1422.3, 2029.0, 1524.3, 2155.7, 1454.0, 1960.3, 1792.0, 2025.7, 1552.0, 2092.3, 1425.0, 2225.7, 1766.7],
        0.2: [3694.3, 870.3, 2611.0, 4285.0, 4963.7, 4737.0, 4585.0, 5388.0, 5399.3, 5026.7, 4963.7, 5729.0, 4953.3, 4622.3, 4362.3, 4621.7, 4965.3, 4489.0, 5307.7, 5634.7, 4819.3, 5405.0, 4090.3, 4452.7, 5594.0, 4727.0, 5579.7, 4621.3, 5521.3, 4861.0, 4682.3, 4940.0, 4990.7, 5596.0, 4700.0, 4834.7, 4938.7, 4671.0, 4681.3, 4262.7, 4928.7, 4577.0, 5112.0, 4872.0, 4607.0, 5023.7, 5111.0, 5224.3, 4947.7, 4176.7, 4515.7, 4671.0, 5496.0, 5635.0, 4778.7, 5125.7, 4925.7, 5272.0, 4615.7, 5201.7, 4963.0, 5756.0, 4508.0, 5047.0, 4685.7, 5066.7, 4962.3, 4310.3, 5020.7, 4422.3, 4923.7, 4927.7, 5206.3, 4656.7, 5335.7, 5106.7, 5272.7, 4523.7, 4990.7, 5319.0, 4834.7, 5042.3, 4801.3, 4958.7, 4830.3, 4792.3, 4697.3, 4797.7, 4969.3, 5607.3, 4913.0, 4662.7, 5256.0, 4898.7, 4659.3, 5188.7, 5448.3, 4987.3, 5424.7, 5532.3],
        0.3: [7312.7, 1234.7, 3496.3, 5774.3, 5019.7, 4725.0, 5556.3, 5804.7, 5319.3, 6016.7, 6884.3, 6456.3, 6250.7, 6304.3, 6135.0, 6536.7, 5401.3, 5544.3, 5496.3, 5705.3, 6457.3, 5880.3, 5052.0, 5713.3, 5690.0, 5200.7, 4517.7, 5413.7, 5445.3, 4689.0, 4342.7, 5609.0, 5237.3, 6241.7, 6354.3, 5144.0, 6078.7, 5953.7, 5965.7, 6859.0, 6013.3, 6397.3, 6725.0, 5433.3, 6633.7, 5668.7, 5207.0, 5770.3, 5203.7, 6023.7, 6015.0, 6046.0, 6466.0, 6264.3, 6674.3, 6499.3, 7314.7, 5685.3, 6611.0, 7276.7, 6523.3, 7583.3, 6659.3, 7309.7, 6750.3, 6070.3, 6167.3, 7180.0, 6343.0, 6701.0, 7274.0, 7353.3, 6391.3, 6655.3, 6525.7, 7769.3, 6341.0, 6848.7, 6918.3, 7014.3, 7827.0, 7766.0, 7809.7, 6994.3, 8177.3, 7229.0, 6922.3, 7388.3, 7247.3, 7692.7, 7521.0, 7331.7, 6966.7, 7025.0, 7490.7, 8057.7, 8109.3, 7480.7, 7267.7, 6853.7],
        0.4: [8998.3, 4538.0, 5600.7, 6654.7, 4607.3, 7517.0, 5957.0, 5007.7, 5959.7, 6515.7, 5455.3, 5027.3, 6063.0, 7323.7, 6607.3, 7120.7, 6101.3, 6445.0, 6173.7, 7981.3, 5620.0, 7393.7, 6398.3, 7157.7, 7183.0, 6780.3, 6594.0, 6283.0, 7385.3, 6912.7, 6904.0, 6265.0, 5828.7, 6266.7, 7054.3, 7738.3, 7232.0, 7378.0, 7111.7, 7317.7, 7818.0, 7651.0, 6953.3, 8256.3, 7008.0, 6612.0, 7896.7, 7669.3, 7808.0, 7459.0, 7152.7, 7451.3, 7904.7, 7963.0, 7270.0, 7155.0, 7097.3, 7062.0, 8757.0, 7262.3, 6921.0, 7305.0, 7901.0, 7644.7, 7044.0, 6985.3, 7014.3, 6804.0, 7305.7, 7315.7, 7788.7, 8041.7, 7126.7, 7792.3, 7926.3, 6587.3, 8755.7, 8060.7, 8338.0, 7599.0, 7447.0, 7987.0, 8342.0, 7443.7, 7261.3, 7420.3, 6782.7, 6761.7, 8353.3, 6646.0, 6956.0, 6769.7, 8494.3, 7817.0, 7472.7, 7025.7, 7729.3, 7758.3, 6810.3, 7530.0],
        0.5: [10105.0, 7307.7, 7055.3, 7454.3, 6351.3, 5049.7, 4119.0, 6250.0, 6657.3, 6131.7, 7045.0, 6515.3, 5699.7, 5894.3, 7086.3, 6383.0, 6583.3, 7188.3, 7294.3, 7571.3, 7585.7, 6887.7, 6465.7, 6641.7, 6857.0, 7962.0, 8362.3, 10065.3, 7886.0, 7844.7, 7829.3, 7513.0, 6202.0, 7785.3, 6631.7, 7278.0, 6836.0, 7606.7, 6851.7, 7013.7, 7116.3, 7849.0, 7950.0, 7191.0, 6025.3, 7024.3, 6635.0, 6829.7, 6819.0, 7240.3, 7159.3, 7677.7, 6931.3, 6468.3, 7942.0, 7099.3, 6849.7, 7049.3, 7038.7, 7303.7, 7154.0, 7069.0, 7931.3, 7281.3, 8132.7, 8019.7, 7062.3, 8271.0, 7671.3, 7712.7, 8334.3, 8786.0, 8095.0, 8378.0, 8191.0, 8272.7, 8426.0, 7871.3, 8168.0, 7771.3, 8646.0, 8745.7, 7926.7, 7528.7, 8318.7, 7174.7, 7003.3, 8457.3, 8255.7, 7975.3, 7754.7, 7682.7, 8020.0, 8009.3, 7759.7, 6822.7, 7880.7, 7659.7, 7899.3, 8158.7],
        0.6: [9701.7, 9204.7, 8277.0, 8206.7, 6110.7, 5327.0, 5800.3, 5817.3, 5602.7, 6038.3, 6438.3, 7981.3, 6764.0, 6806.7, 7974.7, 8062.7, 5701.3, 7780.0, 6509.7, 9161.0, 6378.7, 6501.3, 6439.7, 5771.0, 6650.0, 6591.0, 6841.7, 5896.0, 6250.7, 5977.7, 5946.0, 7054.3, 5410.7, 6103.0, 6613.0, 6279.7, 6659.3, 6668.0, 6072.7, 7353.3, 6125.3, 6285.7, 5946.0, 6392.7, 8366.3, 6876.3, 6295.7, 7292.7, 6456.7, 7588.3, 6460.3, 7369.7, 7372.0, 8474.3, 7618.7, 7252.7, 7234.3, 8130.7, 6166.3, 7500.7, 7774.3, 7123.0, 5455.7, 6999.3, 6739.3, 5846.7, 8241.3, 8159.7, 8012.0, 7473.3, 6450.0, 7693.3, 6871.0, 7112.3, 7104.7, 7112.0, 9094.0, 7375.0, 7333.0, 7436.0, 7309.0, 6293.0, 6856.0, 7754.3, 8369.3, 7875.3, 6818.3, 8109.3, 7595.7, 7641.3, 8225.3, 8991.3, 8146.3, 9318.0, 9304.0, 8972.3, 8362.3, 9533.7, 10508.0, 8447.0],
        0.7: [11548.7, 10101.7, 9565.0, 8395.7, 7264.3, 7950.3, 5774.3, 6967.7, 6774.7, 7445.7, 4844.7, 8466.3, 6381.0, 6465.7, 6243.3, 7347.0, 6689.0, 7044.3, 7767.0, 8138.0, 7673.3, 8477.3, 7658.0, 7694.3, 8543.3, 9196.3, 7323.7, 8138.7, 7195.0, 7697.3, 7237.7, 7786.0, 8946.3, 9437.3, 8550.7, 9172.3, 9058.0, 7726.7, 8655.3, 8435.3, 8402.7, 9090.0, 9437.7, 9488.0, 8698.7, 8496.3, 10464.0, 11041.0, 10146.7, 8934.7, 9583.7, 12317.3, 10801.3, 9967.3, 7858.7, 8849.0, 10139.7, 9285.7, 9504.3, 8968.7, 10962.7, 9882.3, 10571.3, 11388.7, 9488.7, 10131.0, 9791.0, 9972.3, 12201.7, 10289.3, 11531.3, 10638.7, 11906.7, 11525.3, 10894.0, 11292.3, 10920.0, 11008.3, 11994.7, 10651.7, 11152.3, 11988.7, 12367.0, 11337.3, 10974.3, 10603.3, 11163.3, 11282.0, 12213.7, 11648.7, 11392.3, 12428.0, 12617.3, 13005.3, 11352.7, 11766.0, 11563.0, 11664.3, 11298.7, 12691.0],
        0.8: [13700.7, 10814.3, 9907.3, 10836.0, 8487.3, 8751.0, 6656.3, 7559.0, 9027.0, 7485.3, 6863.3, 6973.3, 7688.7, 6455.7, 6039.0, 7199.7, 6834.3, 6701.0, 7139.3, 8707.0, 7564.0, 6554.0, 6309.3, 7435.7, 7078.0, 6856.0, 6508.0, 7016.7, 7082.3, 8535.0, 7619.7, 6446.3, 6174.3, 5623.7, 6689.7, 6208.0, 6762.0, 7369.7, 7184.7, 7766.0, 7314.0, 7848.0, 7003.7, 6767.0, 7004.7, 6705.3, 6619.0, 6757.7, 7007.0, 7065.0, 6893.3, 7070.0, 7941.0, 7268.0, 8402.7, 7861.0, 7878.7, 7816.3, 7837.3, 6866.3, 7474.3, 7486.3, 7318.7, 7747.7, 7224.3, 6925.3, 7070.7, 7817.7, 7672.0, 7828.0, 7689.0, 7545.7, 7311.3, 7416.0, 7331.0, 8127.0, 7064.0, 7052.7, 7732.0, 8091.3, 8170.0, 8026.7, 8079.0, 8064.7, 7875.3, 7728.3, 8138.0, 8084.7, 8226.3, 7541.7, 7516.0, 8294.3, 7198.0, 7925.0, 7774.0, 7662.0, 8045.0, 8025.0, 7922.3, 8090.3], 
        0.9: [13803.0, 12227.0, 11144.3, 11289.3, 8498.7, 8595.3, 8461.0, 7552.0, 7502.3, 6144.3, 8580.0, 8180.3, 8666.0, 7728.3, 8698.3, 10486.7, 8322.7, 10291.7, 9427.7, 7882.7, 6946.7, 7438.7, 9612.3, 8567.7, 8313.3, 9912.0, 8688.7, 8144.7, 9992.3, 8302.7, 8361.0, 8287.3, 9030.3, 7502.0, 7829.0, 8770.7, 8168.0, 8413.7, 9309.0, 9235.7, 9709.0, 10442.7, 10067.7, 10257.0, 10329.3, 10962.3, 9784.0, 11463.3, 11114.3, 10374.0, 9572.3, 9786.3, 10140.0, 10989.0, 12931.3, 9533.0, 10655.0, 11183.3, 9820.7, 8295.0, 9317.0, 9981.0, 7738.7, 10853.3, 11006.7, 7981.3, 7491.0, 8565.3, 7677.3, 7912.3, 9340.7, 9744.7, 8487.0, 7893.7, 7057.3, 8276.3, 6715.3, 7176.0, 8978.3, 7430.3, 8905.3, 8889.0, 7168.7, 9466.3, 9842.7, 10063.7, 9354.7, 10361.7, 10875.7, 9657.0, 11688.7, 11003.7, 9832.7, 10627.7, 11246.3, 10768.3, 10204.7, 9955.0, 11328.0, 10524.7],
        1.0: [12106.3, 13469.0, 13492.7, 12601.0, 9558.0, 10501.7, 10897.0, 9206.7, 7373.0, 9385.7, 8668.3, 9667.3, 9852.3, 8130.3, 9529.7, 8546.7, 9555.7, 9407.3, 9146.3, 9593.3, 10869.3, 9492.7, 9455.0, 10287.3, 11371.0, 10043.3, 10400.3, 10233.7, 10604.7, 11596.7, 10396.3, 9581.7, 10729.7, 11188.7, 9946.7, 10986.7, 11282.0, 10993.3, 10819.7, 10893.3, 11052.0, 10215.3, 9569.7, 10434.7, 10395.3, 10699.7, 10219.0, 10309.3, 11167.3, 10896.3, 11308.0, 11108.3, 11042.0, 11118.7, 10907.7, 11422.0, 11326.7, 10690.7, 10801.3, 10754.3, 10450.3, 11014.7, 10702.7, 10486.7, 10794.0, 10773.0, 9913.7, 9970.3, 10465.3, 10808.3, 10974.3, 11984.0, 11299.7, 11016.3, 10685.3, 10185.7, 10682.3, 11190.0, 11032.7, 11723.3, 10938.0, 12045.7, 11624.3, 11718.7, 13826.0, 12713.0, 13577.7, 13374.7, 12910.0, 12384.3, 12591.0, 12757.7, 12908.0, 12098.0, 13034.3, 12658.7, 12956.0, 12476.3, 12854.3, 12292.0]
    }

    plt.figure(figsize=(12, 8))
    for key, values in data.items():
        plt.plot(values, linewidth=2, label=key)

    fontsize = 18
    plt.legend(fontsize=fontsize, loc='lower left', bbox_to_anchor=(1, 0))
    plt.grid()
    plt.xticks(fontsize=fontsize)
    plt.yticks(fontsize=fontsize)
    plt.title('Federated - WineQuality - 3 clients linear local evaluation - 100 rounds', fontsize=20)
    plt.xlabel('Rounds', fontsize=fontsize)
    plt.ylabel('Model size in bytes', fontsize=fontsize)

    plt.tight_layout()
    plt.savefig('_static/model_size_wine_quality_3_linear_local_100.png')

# load_dataset_try()
# visualise()

# mvs_simulation_centralized()

dataset_analysis()

def calculate_average(filename):
    with open(filename, 'r') as file:
        reader = csv.reader(file)
        numbers = [int(row[0]) for row in reader]
        return sum(numbers) / len(numbers) if numbers else 0

averages = []

# Assuming the CSV files are named '1.csv', '2.csv', ..., '100.csv'
for i in range(1, 101):
    filename = f'./_static/{i}.csv'
    if os.path.exists(filename):
        avg = calculate_average(filename)
        averages.append(round(avg, 1))
        os.remove(filename)
    else:
        averages.append(None)  # Or handle the missing file case as needed

# Output the list of averages
print(averages)
print("average: ", sum(averages) / len(averages))
